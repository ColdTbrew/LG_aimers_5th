{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a946f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns removed due to having only 1 unique value: ['Wip Line_Dam', 'Process Desc._Dam', 'Insp. Seq No._Dam', 'Insp Judge Code_Dam', 'CURE STANDBY POSITION X Collect Result_Dam', 'CURE STANDBY POSITION Z Collect Result_Dam', 'CURE STANDBY POSITION Θ Collect Result_Dam', 'CURE START POSITION Z Collect Result_Dam', 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam', 'Wip Line_AutoClave', 'Process Desc._AutoClave', 'Equipment_AutoClave', 'Insp. Seq No._AutoClave', 'Insp Judge Code_AutoClave', '1st Pressure Judge Value_AutoClave', '2nd Pressure Judge Value_AutoClave', '3rd Pressure Judge Value_AutoClave', 'GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave', 'GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave', 'Wip Line_Fill1', 'Process Desc._Fill1', 'Insp. Seq No._Fill1', 'Insp Judge Code_Fill1', 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1', 'Wip Line_Fill2', 'Process Desc._Fill2', 'Insp. Seq No._Fill2', 'Insp Judge Code_Fill2', 'CURE END POSITION Θ Collect Result_Fill2', 'CURE STANDBY POSITION X Collect Result_Fill2', 'CURE STANDBY POSITION Θ Collect Result_Fill2', 'CURE START POSITION Θ Collect Result_Fill2', 'DISCHARGED SPEED OF RESIN Collect Result_Fill2', 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill2', 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill2', 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill2', 'Dispense Volume(Stage1) Collect Result_Fill2', 'Dispense Volume(Stage2) Collect Result_Fill2', 'Dispense Volume(Stage3) Collect Result_Fill2', 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2']\n",
      "Column 'Equipment_Dam' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Model.Suffix_Dam' has 7 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Workorder_Dam' has 663 unique values (> 5).\n",
      "Column 'CURE END POSITION X Collect Result_Dam' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'CURE END POSITION Z Collect Result_Dam' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'CURE END POSITION Θ Collect Result_Dam' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'CURE SPEED Collect Result_Dam' has 5 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'CURE START POSITION X Collect Result_Dam' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'CURE START POSITION Θ Collect Result_Dam' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'DISCHARGED SPEED OF RESIN Collect Result_Dam' has 3 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam' has 19 unique values (> 5).\n",
      "Column 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam' has 29 unique values (> 5).\n",
      "Column 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam' has 20 unique values (> 5).\n",
      "Column 'Dispense Volume(Stage1) Collect Result_Dam' has 23 unique values (> 5).\n",
      "Column 'Dispense Volume(Stage2) Collect Result_Dam' has 33 unique values (> 5).\n",
      "Column 'Dispense Volume(Stage3) Collect Result_Dam' has 22 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam' has 7 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam' has 41 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam' has 40 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam' has 36 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam' has 16 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam' has 15 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam' has 16 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam' has 24 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam' has 24 unique values (> 5).\n",
      "Column 'HEAD Standby Position X Collect Result_Dam' has 23 unique values (> 5).\n",
      "Column 'HEAD Standby Position Y Collect Result_Dam' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD Standby Position Z Collect Result_Dam' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Clean Position X Collect Result_Dam' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Clean Position Y Collect Result_Dam' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Clean Position Z Collect Result_Dam' has 4 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Purge Position X Collect Result_Dam' has 4 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Purge Position Y Collect Result_Dam' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Purge Position Z Collect Result_Dam' has 4 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Zero Position X Collect Result_Dam' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Zero Position Y Collect Result_Dam' has 3 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Zero Position Z Collect Result_Dam' has 3 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Machine Tact time Collect Result_Dam' has 266 unique values (> 5).\n",
      "Column 'PalletID Collect Result_Dam' has 374 unique values (> 5).\n",
      "Column 'Production Qty Collect Result_Dam' has 486 unique values (> 5).\n",
      "Column 'Receip No Collect Result_Dam' has 607 unique values (> 5).\n",
      "Column 'Stage1 Circle1 Distance Speed Collect Result_Dam' has 8 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage1 Circle2 Distance Speed Collect Result_Dam' has 7 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage1 Circle3 Distance Speed Collect Result_Dam' has 7 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage1 Circle4 Distance Speed Collect Result_Dam' has 7 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage1 Line1 Distance Speed Collect Result_Dam' has 8 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage1 Line2 Distance Speed Collect Result_Dam' has 8 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage1 Line3 Distance Speed Collect Result_Dam' has 8 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage1 Line4 Distance Speed Collect Result_Dam' has 8 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage2 Circle1 Distance Speed Collect Result_Dam' has 8 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage2 Circle2 Distance Speed Collect Result_Dam' has 9 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage2 Circle3 Distance Speed Collect Result_Dam' has 9 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage2 Circle4 Distance Speed Collect Result_Dam' has 9 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage2 Line1 Distance Speed Collect Result_Dam' has 9 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage2 Line2 Distance Speed Collect Result_Dam' has 9 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage2 Line3 Distance Speed Collect Result_Dam' has 10 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage2 Line4 Distance Speed Collect Result_Dam' has 9 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage3 Circle1 Distance Speed Collect Result_Dam' has 10 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage3 Circle2 Distance Speed Collect Result_Dam' has 7 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage3 Circle3 Distance Speed Collect Result_Dam' has 7 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage3 Circle4 Distance Speed Collect Result_Dam' has 7 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage3 Line1 Distance Speed Collect Result_Dam' has 8 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage3 Line2 Distance Speed Collect Result_Dam' has 7 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage3 Line3 Distance Speed Collect Result_Dam' has 8 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Stage3 Line4 Distance Speed Collect Result_Dam' has 7 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'THICKNESS 1 Collect Result_Dam' has 6 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'THICKNESS 2 Collect Result_Dam' has 7 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'THICKNESS 3 Collect Result_Dam' has 8 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'WorkMode Collect Result_Dam' has 8 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Model.Suffix_AutoClave' has 7 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Workorder_AutoClave' has 663 unique values (> 5).\n",
      "Column '1st Pressure Collect Result_AutoClave' has 27 unique values (> 5).\n",
      "Column '1st Pressure 1st Pressure Unit Time_AutoClave' has 9 unique values (<= 5). Consider converting to categorical.\n",
      "Column '2nd Pressure Collect Result_AutoClave' has 67 unique values (> 5).\n",
      "Column '2nd Pressure Unit Time_AutoClave' has 10 unique values (<= 5). Consider converting to categorical.\n",
      "Column '3rd Pressure Collect Result_AutoClave' has 67 unique values (> 5).\n",
      "Column '3rd Pressure Unit Time_AutoClave' has 11 unique values (> 5).\n",
      "Column 'Chamber Temp. Collect Result_AutoClave' has 26 unique values (> 5).\n",
      "Column 'Chamber Temp. Unit Time_AutoClave' has 24 unique values (> 5).\n",
      "Column 'Chamber Temp. Judge Value_AutoClave' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Equipment_Fill1' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Model.Suffix_Fill1' has 7 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Workorder_Fill1' has 663 unique values (> 5).\n",
      "Column 'DISCHARGED SPEED OF RESIN Collect Result_Fill1' has 4 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1' has 16 unique values (> 5).\n",
      "Column 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1' has 24 unique values (> 5).\n",
      "Column 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1' has 16 unique values (> 5).\n",
      "Column 'Dispense Volume(Stage1) Collect Result_Fill1' has 16 unique values (> 5).\n",
      "Column 'Dispense Volume(Stage2) Collect Result_Fill1' has 27 unique values (> 5).\n",
      "Column 'Dispense Volume(Stage3) Collect Result_Fill1' has 16 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1' has 5 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1' has 18 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1' has 20 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1' has 12 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1' has 19 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1' has 15 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1' has 20 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1' has 19 unique values (> 5).\n",
      "Column 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1' has 18 unique values (> 5).\n",
      "Column 'HEAD Standby Position X Collect Result_Fill1' has 18 unique values (> 5).\n",
      "Column 'HEAD Standby Position Y Collect Result_Fill1' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD Standby Position Z Collect Result_Fill1' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Clean Position X Collect Result_Fill1' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Clean Position Y Collect Result_Fill1' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Clean Position Z Collect Result_Fill1' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Purge Position X Collect Result_Fill1' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Purge Position Y Collect Result_Fill1' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Purge Position Z Collect Result_Fill1' has 3 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Machine Tact time Collect Result_Fill1' has 194 unique values (> 5).\n",
      "Column 'PalletID Collect Result_Fill1' has 301 unique values (> 5).\n",
      "Column 'Production Qty Collect Result_Fill1' has 486 unique values (> 5).\n",
      "Column 'Receip No Collect Result_Fill1' has 607 unique values (> 5).\n",
      "Column 'WorkMode Collect Result_Fill1' has 7 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Equipment_Fill2' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Model.Suffix_Fill2' has 7 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Workorder_Fill2' has 663 unique values (> 5).\n",
      "Column 'CURE END POSITION X Collect Result_Fill2' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'CURE END POSITION Z Collect Result_Fill2' has 3 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'CURE SPEED Collect Result_Fill2' has 8 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'CURE STANDBY POSITION Z Collect Result_Fill2' has 4 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'CURE START POSITION X Collect Result_Fill2' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'CURE START POSITION Z Collect Result_Fill2' has 4 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2' has 3 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2' has 5 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2' has 4 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2' has 5 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2' has 3 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2' has 3 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2' has 4 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD Standby Position X Collect Result_Fill2' has 3 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD Standby Position Y Collect Result_Fill2' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'HEAD Standby Position Z Collect Result_Fill2' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Clean Position X Collect Result_Fill2' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Clean Position Y Collect Result_Fill2' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Clean Position Z Collect Result_Fill2' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Purge Position X Collect Result_Fill2' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Purge Position Y Collect Result_Fill2' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Head Purge Position Z Collect Result_Fill2' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'Machine Tact time Collect Result_Fill2' has 42 unique values (> 5).\n",
      "Column 'PalletID Collect Result_Fill2' has 89 unique values (> 5).\n",
      "Column 'Production Qty Collect Result_Fill2' has 486 unique values (> 5).\n",
      "Column 'Receip No Collect Result_Fill2' has 607 unique values (> 5).\n",
      "Column 'WorkMode Collect Result_Fill2' has 6 unique values (<= 5). Consider converting to categorical.\n",
      "Column 'target' has 2 unique values (<= 5). Consider converting to categorical.\n",
      "Object columns to be converted: Index(['Workorder_Dam', 'Workorder_AutoClave', 'Workorder_Fill1',\n",
      "       'Workorder_Fill2'],\n",
      "      dtype='object')\n",
      "\n",
      "Final DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 146 entries, Equipment_Dam to target\n",
      "dtypes: category(98), float64(39), int64(9)\n",
      "memory usage: 18.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "ROOT_DIR = \".\"\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv(os.path.join(ROOT_DIR, \"train.csv\"))\n",
    "df = train_data.copy()\n",
    "# Drop columns with all NaN values\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# 값이 1인 열 제거\n",
    "cols_to_remove = [col for col in df.columns if df[col].nunique() == 1]\n",
    "df = df.drop(columns=cols_to_remove)\n",
    "\n",
    "print(\"Columns removed due to having only 1 unique value:\", cols_to_remove)\n",
    "\n",
    "# OK 값 제거\n",
    "df['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] = df['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].replace(\"OK\", np.nan)\n",
    "\n",
    "# 숫자형 열의 고유 값 개수 확인 및 범주형으로 변환\n",
    "for col in df.columns:\n",
    "    unique_count = df[col].nunique()\n",
    "    if unique_count <= 10:\n",
    "        print(f\"Column '{col}' has {unique_count} unique values (<= 5). Consider converting to categorical.\")\n",
    "        df[col] = df[col].astype('category')\n",
    "    else:\n",
    "        print(f\"Column '{col}' has {unique_count} unique values (> 5).\")\n",
    "\n",
    "# 'object' 타입 열 확인\n",
    "object_cols = df.select_dtypes(include=['object']).columns\n",
    "print(\"Object columns to be converted:\", object_cols)\n",
    "\n",
    "# 범주형 데이터로 변환\n",
    "for col in object_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# # 범주형으로 변환된 열 확인\n",
    "# categorical_cols = df.select_dtypes(include=['category'])\n",
    "\n",
    "# 예시로 target 컬럼 이름이 'target'이라고 가정\n",
    "df['target'] = df['target'].map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "# 최종 데이터프레임 정보 출력\n",
    "train_df = df.copy()\n",
    "print(\"\\nFinal DataFrame:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f2ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "# from sklearn.metrics import f1_score, recall_score, accuracy_score, classification_report\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# # 데이터 준비\n",
    "# X = train_df.drop(columns=['target'])  # 피처 데이터\n",
    "# y = train_df['target']  # 타겟 데이터\n",
    "\n",
    "# # 학습 데이터와 테스트 데이터로 분할\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# # LGBMClassifier 모델 설정\n",
    "# lgbm_model = lgb.LGBMClassifier(\n",
    "#     objective='binary',\n",
    "#     boosting_type='gbdt',\n",
    "#     metric='f1',  # f1 score를 평가 지표로 사용\n",
    "#     is_unbalance=True,  # 데이터 불균형일 경우\n",
    "#     learning_rate=0.01,\n",
    "#     num_leaves=250,\n",
    "#     max_depth=-1,\n",
    "#     feature_fraction=0.9,\n",
    "#     bagging_fraction=0.8,\n",
    "#     bagging_freq=5,\n",
    "#     class_weight={0: 1, 1: 1},  # 클래스 1의 가중치를 높임\n",
    "#     n_estimators=500,  # 최대 부스팅 라운드 수\n",
    "# )\n",
    "# # 모델 학습\n",
    "# lgbm_model.fit(\n",
    "#     X_train, y_train,\n",
    "#     eval_set=[(X_test, y_test)],\n",
    "#     eval_metric='f1',\n",
    "# )\n",
    "\n",
    "# lgbm_model.booster_.save_model(os.path.join(ROOT_DIR, \"lgbm_model.txt\"))\n",
    "\n",
    "# # 예측 수행\n",
    "# y_pred = lgbm_model.predict(X_test)\n",
    "\n",
    "# # 평가\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(f\"F1 Score: {f1}\")\n",
    "# print(f\"Recall: {recall}\")\n",
    "# print(f\"Accuracy: {accuracy}\")\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1de134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install optuna-integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c85f69f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Total Bins 6124[LightGBM] [Info] Start training from score -2.787274\n",
      "\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=16, n_estimators=200, num_leaves=150;, score=0.199 total time=  36.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=16, n_estimators=200, num_leaves=150;, score=0.220 total time=  36.5s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=16, n_estimators=200, num_leaves=150;, score=0.198 total time=  36.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=16, n_estimators=200, num_leaves=150;, score=0.216 total time=  36.9s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "\n",
      "[LightGBM] [Info] Total Bins 6112[LightGBM] [Info] Total Bins 6129\n",
      "\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=16, n_estimators=200, num_leaves=150;, score=0.194 total time=  43.3s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=16, n_estimators=200, num_leaves=250;, score=0.198 total time=  58.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=16, n_estimators=200, num_leaves=250;, score=0.222 total time=  59.1s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=16, n_estimators=200, num_leaves=250;, score=0.208 total time=  59.7s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=16, n_estimators=200, num_leaves=250;, score=0.214 total time= 1.0min\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=16, n_estimators=200, num_leaves=250;, score=0.206 total time= 1.1min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=16, n_estimators=250, num_leaves=150;, score=0.213 total time=  45.0s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=16, n_estimators=200, num_leaves=400;, score=0.214 total time= 1.6min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=16, n_estimators=250, num_leaves=150;, score=0.204 total time=  44.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=16, n_estimators=250, num_leaves=150;, score=0.205 total time=  45.2s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=16, n_estimators=250, num_leaves=150;, score=0.198 total time=  45.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=16, n_estimators=250, num_leaves=150;, score=0.215 total time=  46.0s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=16, n_estimators=200, num_leaves=400;, score=0.207 total time= 1.4min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=16, n_estimators=200, num_leaves=400;, score=0.196 total time= 1.4min\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=16, n_estimators=200, num_leaves=400;, score=0.182 total time= 1.5min\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=16, n_estimators=200, num_leaves=400;, score=0.191 total time= 1.6min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=16, n_estimators=250, num_leaves=250;, score=0.208 total time= 1.2min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=16, n_estimators=250, num_leaves=250;, score=0.209 total time= 1.2min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=32, n_estimators=200, num_leaves=150;, score=0.213 total time=  37.8s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=16, n_estimators=250, num_leaves=250;, score=0.209 total time= 1.2min\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=16, n_estimators=250, num_leaves=250;, score=0.210 total time= 1.2min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=32, n_estimators=200, num_leaves=150;, score=0.212 total time=  40.2s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=16, n_estimators=250, num_leaves=250;, score=0.203 total time= 1.4min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=32, n_estimators=200, num_leaves=150;, score=0.181 total time=  39.1s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=32, n_estimators=200, num_leaves=150;, score=0.198 total time=  39.6s\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=32, n_estimators=200, num_leaves=150;, score=0.210 total time=  38.1s\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=16, n_estimators=250, num_leaves=400;, score=0.219 total time= 2.0min\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=16, n_estimators=250, num_leaves=400;, score=0.196 total time= 2.1min\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=16, n_estimators=250, num_leaves=400;, score=0.190 total time= 1.8min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=16, n_estimators=250, num_leaves=400;, score=0.211 total time= 1.8min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=32, n_estimators=200, num_leaves=250;, score=0.215 total time= 1.1min\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=16, n_estimators=250, num_leaves=400;, score=0.205 total time= 2.0min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=32, n_estimators=200, num_leaves=250;, score=0.194 total time= 1.1min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=32, n_estimators=200, num_leaves=250;, score=0.201 total time= 1.2min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=32, n_estimators=200, num_leaves=250;, score=0.199 total time= 1.1min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=32, n_estimators=200, num_leaves=250;, score=0.227 total time= 1.1min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=32, n_estimators=250, num_leaves=150;, score=0.212 total time=  46.2s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=32, n_estimators=250, num_leaves=150;, score=0.211 total time=  48.7s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=32, n_estimators=250, num_leaves=150;, score=0.188 total time=  47.4s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=32, n_estimators=250, num_leaves=150;, score=0.191 total time=  49.0s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=32, n_estimators=250, num_leaves=150;, score=0.208 total time=  47.3s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=32, n_estimators=200, num_leaves=400;, score=0.214 total time= 1.6min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=32, n_estimators=200, num_leaves=400;, score=0.188 total time= 1.7min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=32, n_estimators=200, num_leaves=400;, score=0.184 total time= 1.6min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=32, n_estimators=200, num_leaves=400;, score=0.203 total time= 1.6min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=32, n_estimators=200, num_leaves=400;, score=0.209 total time= 1.7min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=32, n_estimators=250, num_leaves=250;, score=0.212 total time= 1.3min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=32, n_estimators=250, num_leaves=250;, score=0.223 total time= 1.3min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=64, n_estimators=200, num_leaves=150;, score=0.220 total time=  38.4s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=32, n_estimators=250, num_leaves=250;, score=0.198 total time= 1.3min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=32, n_estimators=250, num_leaves=250;, score=0.235 total time= 1.3min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=32, n_estimators=250, num_leaves=250;, score=0.191 total time= 1.5min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=64, n_estimators=200, num_leaves=150;, score=0.199 total time=  45.1s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=64, n_estimators=200, num_leaves=150;, score=0.188 total time=  38.6s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=64, n_estimators=200, num_leaves=150;, score=0.203 total time=  39.9s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=64, n_estimators=200, num_leaves=150;, score=0.210 total time=  38.7s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.276175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=32, n_estimators=250, num_leaves=400;, score=0.210 total time= 2.0min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=32, n_estimators=250, num_leaves=400;, score=0.188 total time= 2.0min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=64, n_estimators=200, num_leaves=250;, score=0.214 total time= 1.0min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=64, n_estimators=200, num_leaves=250;, score=0.206 total time= 1.1min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=32, n_estimators=250, num_leaves=400;, score=0.210 total time= 2.0min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=64, n_estimators=200, num_leaves=250;, score=0.190 total time= 1.1min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=32, n_estimators=250, num_leaves=400;, score=0.198 total time= 2.3min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=32, n_estimators=250, num_leaves=400;, score=0.214 total time= 2.3min\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=64, n_estimators=200, num_leaves=250;, score=0.199 total time= 1.1min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=64, n_estimators=200, num_leaves=250;, score=0.221 total time= 1.1min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=64, n_estimators=250, num_leaves=150;, score=0.209 total time=  48.4s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=64, n_estimators=250, num_leaves=150;, score=0.209 total time=  48.6s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=64, n_estimators=200, num_leaves=400;, score=0.216 total time= 1.7min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=64, n_estimators=250, num_leaves=150;, score=0.190 total time=  49.7s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=64, n_estimators=250, num_leaves=150;, score=0.206 total time=  48.9s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6127\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=64, n_estimators=250, num_leaves=150;, score=0.214 total time=  49.6s\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6124\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=64, n_estimators=200, num_leaves=400;, score=0.196 total time= 1.7min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6101\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=64, n_estimators=200, num_leaves=400;, score=0.200 total time= 1.7min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6129\n",
      "[LightGBM] [Info] Number of data points in the train set: 25923, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787233\n",
      "[LightGBM] [Info] Start training from score -2.787233\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=64, n_estimators=200, num_leaves=400;, score=0.208 total time= 1.7min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1504, number of negative: 24420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.171871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6112\n",
      "[LightGBM] [Info] Number of data points in the train set: 25924, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058016 -> initscore=-2.787274\n",
      "[LightGBM] [Info] Start training from score -2.787274\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=64, n_estimators=200, num_leaves=400;, score=0.180 total time= 1.9min\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=64, n_estimators=250, num_leaves=250;, score=0.216 total time= 1.3min\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=64, n_estimators=250, num_leaves=250;, score=0.212 total time= 1.3min\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=64, n_estimators=250, num_leaves=250;, score=0.190 total time= 1.2min\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=64, n_estimators=250, num_leaves=250;, score=0.200 total time= 1.2min\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=64, n_estimators=250, num_leaves=250;, score=0.222 total time= 1.2min\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=64, n_estimators=250, num_leaves=400;, score=0.189 total time= 1.4min\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=64, n_estimators=250, num_leaves=400;, score=0.189 total time= 1.3min\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=64, n_estimators=250, num_leaves=400;, score=0.219 total time= 1.5min\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=64, n_estimators=250, num_leaves=400;, score=0.206 total time= 1.1min\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=64, n_estimators=250, num_leaves=400;, score=0.203 total time= 1.1min\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1880, number of negative: 30524\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6173\n",
      "[LightGBM] [Info] Number of data points in the train set: 32404, number of used features: 145\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058018 -> initscore=-2.787241\n",
      "[LightGBM] [Info] Start training from score -2.787241\n",
      "Best parameters found by GridSearchCV:\n",
      "{'learning_rate': 0.01, 'max_depth': 32, 'n_estimators': 250, 'num_leaves': 250}\n",
      "F1 Score: 0.21908713692946058\n",
      "Recall: 0.28085106382978725\n",
      "Accuracy: 0.8838558380646754\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      7632\n",
      "           1       0.18      0.28      0.22       470\n",
      "\n",
      "    accuracy                           0.88      8102\n",
      "   macro avg       0.57      0.60      0.58      8102\n",
      "weighted avg       0.91      0.88      0.90      8102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Model file data/lgbm_best_model.txt is not available for writes\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Model file data/lgbm_best_model.txt is not available for writes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# 모델 저장\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbooster_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mROOT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlgbm_best_model.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py:4194\u001b[0m, in \u001b[0;36mBooster.save_model\u001b[0;34m(self, filename, num_iteration, start_iteration, importance_type)\u001b[0m\n\u001b[1;32m   4192\u001b[0m     num_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_iteration\n\u001b[1;32m   4193\u001b[0m importance_type_int \u001b[38;5;241m=\u001b[39m _FEATURE_IMPORTANCE_TYPE_MAPPER[importance_type]\n\u001b[0;32m-> 4194\u001b[0m \u001b[43m_safe_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterSaveModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimportance_type_int\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4199\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4200\u001b[0m _dump_pandas_categorical(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical, filename)\n\u001b[1;32m   4201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py:263\u001b[0m, in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    The return value from C API calls.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB\u001b[38;5;241m.\u001b[39mLGBM_GetLastError()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Model file data/lgbm_best_model.txt is not available for writes"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 데이터 준비\n",
    "X = train_df.drop(columns=['target'])  # 피처 데이터\n",
    "y = train_df['target']  # 타겟 데이터\n",
    "\n",
    "# 학습 데이터와 테스트 데이터로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01],\n",
    "    'num_leaves': [150,250,400],\n",
    "    'max_depth': [16,32, 64],\n",
    "#     'subsample': [0.6, 0.8, 1.0],\n",
    "#     'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'n_estimators': [200,250,],\n",
    "}\n",
    "# LGBMClassifier 모델 설정\n",
    "lgbm_model = lgb.LGBMClassifier(objective='binary', is_unbalance=True)\n",
    "\n",
    "# StratifiedKFold 설정\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# GridSearchCV 설정\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgbm_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터 출력\n",
    "print(\"Best parameters found by GridSearchCV:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# 최적의 모델로 예측 수행\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 모델 저장\n",
    "best_model.booster_.save_model(os.path.join('.', \"lgbm_best_model.txt\"))\n",
    "# Best parameters found by GridSearchCV:\n",
    "# {'learning_rate': 0.01, 'max_depth': -1, 'min_child_samples': 50, 'n_estimators': 500, 'num_leaves': 250}\n",
    "# F1 Score: 0.22277227722772278\n",
    "# Recall: 0.2872340425531915\n",
    "# Accuracy: 0.8837324117501851\n",
    "# {'learning_rate': 0.01, 'max_depth': 32, 'n_estimators': 250, 'num_leaves': 250}\n",
    "# F1 Score: 0.21908713692946058\n",
    "# Recall: 0.28085106382978725\n",
    "# Accuracy: 0.8838558380646754\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a253009f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m RANDOM_STATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m110\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 데이터 로드\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m test_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mROOT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 1. NaN 값이 있는 모든 열 제거\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ag/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ag/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/ag/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ag/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/ag/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/test.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 설정값\n",
    "ROOT_DIR = \"data\"\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "# 데이터 로드\n",
    "test_data = pd.read_csv(os.path.join(ROOT_DIR, \"test.csv\"))\n",
    "df = test_data.copy()\n",
    "\n",
    "# 1. NaN 값이 있는 모든 열 제거\n",
    "df = df.drop('Set ID', axis=1)\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# 2. 값이 1인 열 제거\n",
    "cols_to_remove = [col for col in df.columns if df[col].nunique() == 1]\n",
    "df = df.drop(columns=cols_to_remove)\n",
    "\n",
    "# 3. 특정 열의 \"OK\" 값을 NaN으로 대체\n",
    "df['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'] = df['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'].replace(\"OK\", np.nan)\n",
    "\n",
    "# 4. 숫자형 열의 고유 값 개수에 따른 처리\n",
    "for col in df.columns:\n",
    "    unique_count = df[col].nunique()\n",
    "    if unique_count <= 10:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "# 5. 'object' 타입 열을 범주형으로 변환\n",
    "object_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in object_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "# 타겟 열('target')은 학습 시에만 존재하므로, 추론 시에는 제외\n",
    "X_infer = df.copy()\n",
    "\n",
    "# 학습된 모델 불러오기\n",
    "model = lgb.Booster(model_file=os.path.join(ROOT_DIR, \"lgbm_model.txt\"))\n",
    "\n",
    "# 추론\n",
    "y_pred = model.predict(X_infer, num_iteration=model.best_iteration)\n",
    "\n",
    "# 임계값 설정 (0.5 기준)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# 결과 저장\n",
    "output = pd.DataFrame({'id': X_infer.index, 'prediction': y_pred_binary})\n",
    "output.to_csv(os.path.join(ROOT_DIR, \"predictions.csv\"), index=False)\n",
    "\n",
    "print(\"추론 완료 및 결과 저장 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7becbbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 데이터 읽어오기 및 결과 저장\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"target\"] = output['prediction'].map({0: \"Normal\", 1: \"AbNormal\"})\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission0812.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7915bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e030e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb26df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
